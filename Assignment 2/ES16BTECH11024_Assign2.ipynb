{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <div style=\"text-align: center\"> Applied Machine Learning </div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### <div style=\"text-align: right\"> Udit Maniyar<br><br> ES16BTECH11024 </div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Theory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1) Kernels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/1_a.jpg\" style=\"width:800px;height:900px;\">\n",
    "<img src=\"images/1_b.jpg\" style=\"width:800px;height:900px;\">\n",
    "<img src=\"images/1_cd.jpg\" style=\"width:800px;height:900px;\">\n",
    "<img src=\"images/1_e.jpg\" style=\"width:800px;height:900px;\">\n",
    "\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2) Perceptron Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/2_ab.jpg\" style=\"width:600px;height:700px;\">\n",
    "<img src=\"images/2_c.jpg\" style=\"width:600px;height:500px;\">\n",
    "\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3) Nueral Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/3_a.jpg\" style=\"width:600px;height:700px;\">\n",
    "<img src=\"images/3a_pic.png\" style=\"width:600px;height:400px;\">\n",
    "\n",
    "___\n",
    "\n",
    "<img src=\"images/3_b.jpg\" style=\"width:600px;height:400px;\">\n",
    "\n",
    "___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Import All required Things\n",
    "import numpy as np\n",
    "import csv\n",
    "import math\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import timeit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. SVMs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Get Input from Postal Data\n",
    "def postal_get_input():\n",
    "    with open(\"data/postal.train\") as f:\n",
    "        training_data = f.readlines()\n",
    "        #print(training_data)\n",
    "        training_data = [line.rstrip(\"\\n\") for line in training_data]\n",
    "        training_data = [list(map(float, line.split())) for line in training_data]\n",
    "        training_data = np.array(training_data)\n",
    "    train_set = []\n",
    "    for i in range(len(training_data)):\n",
    "        if training_data[i][0]==1 or training_data[i][0]==5:\n",
    "            train_set.append(training_data[i])\n",
    "            \n",
    "            \n",
    "    print (\"Number of records in training data: %d\" % len(train_set))\n",
    "    \n",
    "    test_set = []\n",
    "    with open(\"data/postal.test\") as f:\n",
    "        test_data = f.readlines()\n",
    "        test_data = [line.rstrip(\"\\n\") for line in test_data]\n",
    "        test_data = [list(map(float, line.split())) for line in test_data]\n",
    "        test_data = np.array(test_data)\n",
    "        \n",
    "\n",
    "    for i in range(len(test_data)):\n",
    "        if test_data[i][0]==1 or test_data[i][0]==5:\n",
    "            test_set.append(test_data[i])\n",
    "    train_set = np.array(train_set)\n",
    "    test_set = np.array(test_set)\n",
    "    \n",
    "    print (\"Number of records in test data: %d\" % len(test_set))\n",
    "\n",
    "\n",
    "    return train_set,test_set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### a) Linear Kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Linear SVM\n",
    "def linear_svm(training_data,test_data):\n",
    "    x = training_data[:,1:]\n",
    "    y = []\n",
    "    for i in training_data:\n",
    "        y.append(i[0])\n",
    "    \n",
    "    y = np.array(y)\n",
    "    linear_svm = SVC(kernel = \"linear\")\n",
    "    linear_svm.fit(x,y)\n",
    "    \n",
    "    \n",
    "    train_outcome = linear_svm.predict(x)\n",
    "    train_result = []\n",
    "    for i in range(len(x)):\n",
    "        if train_outcome[i] == y[i]:\n",
    "            train_result.append(True)\n",
    "        else:\n",
    "            train_result.append(False)\n",
    "\n",
    "    train_accuracy = train_result.count(True)/len(x)\n",
    "    \n",
    "    print(\"Training Accuracy: %.8f\" % train_accuracy)\n",
    "    train_error = 1-train_accuracy\n",
    "    print(\"Training Error: %.8f\" % train_error)\n",
    "    \n",
    "    outcome = linear_svm.predict(test_data[:,1:])\n",
    "    result= []\n",
    "    for i in range(len(test_data)):\n",
    "        if outcome[i] == test_data[i][0]:\n",
    "            result.append(True)\n",
    "        else:\n",
    "            result.append(False)\n",
    "            \n",
    "    accuracy = result.count(True)/len(test_data)\n",
    "    print(\"Test accuracy: %.8f\" % accuracy)\n",
    "    test_error = 1-accuracy\n",
    "    print(\"Test Error: %.8f\" % test_error)\n",
    "\n",
    "    support_vectors = linear_svm.support_vectors_\n",
    "    print(\"The number of Support Vectors : \",len(support_vectors))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of records in training data: 1561\n",
      "Number of records in test data: 424\n"
     ]
    }
   ],
   "source": [
    "training_data, test_data = postal_get_input()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Using Complete Data Set\n",
      "Training Accuracy: 0.99615631\n",
      "Training Error: 0.00384369\n",
      "Test accuracy: 0.97877358\n",
      "Test Error: 0.02122642\n",
      "The number of Support Vectors :  28\n"
     ]
    }
   ],
   "source": [
    "print(\"Training Using Complete Data Set\")\n",
    "linear_svm(training_data,test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### (b) In continuation, train only using the first {50, 100, 200, 800} points with the linear kernel. Report the accuracy over the entire test set, and the number of support vectors in each of these cases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----Training Using Only First 50 points----- \n",
      "Training Accuracy: 1.00000000\n",
      "Training Error: 0.00000000\n",
      "Test accuracy: 0.98113208\n",
      "Test Error: 0.01886792\n",
      "The number of Support Vectors :  2\n",
      "----Training Using Only First 100 points----- \n",
      "Training Accuracy: 1.00000000\n",
      "Training Error: 0.00000000\n",
      "Test accuracy: 0.98113208\n",
      "Test Error: 0.01886792\n",
      "The number of Support Vectors :  4\n",
      "----Training Using Only First 200 points----- \n",
      "Training Accuracy: 0.99500000\n",
      "Training Error: 0.00500000\n",
      "Test accuracy: 0.98113208\n",
      "Test Error: 0.01886792\n",
      "The number of Support Vectors :  8\n",
      "----Training Using Only First 800 points----- \n",
      "Training Accuracy: 0.99750000\n",
      "Training Error: 0.00250000\n",
      "Test accuracy: 0.98113208\n",
      "Test Error: 0.01886792\n",
      "The number of Support Vectors :  14\n"
     ]
    }
   ],
   "source": [
    "data_50 = training_data[:50,:]\n",
    "data_100 = training_data[:100,:]\n",
    "data_200 = training_data[:200,:]\n",
    "data_800 = training_data[:800,:]\n",
    "\n",
    "print(\"----Training Using Only First 50 points----- \")\n",
    "linear_svm(data_50,test_data)\n",
    "\n",
    "\n",
    "print(\"----Training Using Only First 100 points----- \")\n",
    "linear_svm(data_100,test_data)\n",
    "\n",
    "\n",
    "print(\"----Training Using Only First 200 points----- \")\n",
    "linear_svm(data_200,test_data)\n",
    "\n",
    "\n",
    "print(\"----Training Using Only First 800 points----- \")\n",
    "linear_svm(data_800,test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Accuracy for training on first 50,100,200,800 is just the same. But the number of support vectors is increseasing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### (c) Polynomial Kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def polynomial_svm(training_data,test_data,c=1,deg = 2):\n",
    "    x = training_data[:,1:]\n",
    "    y = []\n",
    "    for i in training_data:\n",
    "        y.append(i[0])\n",
    "    y = np.array(y)\n",
    "    polynomial_svm = SVC(C = c, kernel = \"poly\",degree = deg,coef0 = 1, gamma = 1)\n",
    "    polynomial_svm.fit(x,y)\n",
    "   \n",
    "\n",
    "    train_outcome = polynomial_svm.predict(x)\n",
    "    train_result= []\n",
    "    for i in range(len(x)):\n",
    "        if train_outcome[i] == y[i]:\n",
    "            train_result.append(True)\n",
    "        else:\n",
    "            train_result.append(False)\n",
    "\n",
    "    train_accuracy = train_result.count(True)/len(x)\n",
    "    print(\"Training Accuracy: %.8f\" % train_accuracy)\n",
    "\n",
    "    train_error = 1-train_accuracy\n",
    "    print(\"Training Error: %.8f\" % train_error)\n",
    "\n",
    "\n",
    "    test_outcome = polynomial_svm.predict(test_data[:,1:])\n",
    "    test_result= []\n",
    "    for i in range(len(test_data)):\n",
    "        if test_outcome[i] == test_data[i][0]:\n",
    "            test_result.append(True)\n",
    "        else:\n",
    "            test_result.append(False)\n",
    "            \n",
    "    test_accuracy = test_result.count(True)/len(test_data)\n",
    "    print(\"Test accuracy: %.8f\" % test_accuracy)\n",
    "    \n",
    "    test_error = 1-test_accuracy\n",
    "    print(\"Test Error: %.8f\" % test_error)\n",
    "\n",
    "    support_vectors = polynomial_svm.support_vectors_\n",
    "    print(\"The number of Support Vectors : \",len(support_vectors))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 0.99103139\n",
      "Training Error: 0.00896861\n",
      "Test accuracy: 0.98349057\n",
      "Test Error: 0.01650943\n",
      "The number of Support Vectors :  236\n",
      "------------------\n",
      "Training Accuracy: 0.99551570\n",
      "Training Error: 0.00448430\n",
      "Test accuracy: 0.98113208\n",
      "Test Error: 0.01886792\n",
      "The number of Support Vectors :  26\n"
     ]
    }
   ],
   "source": [
    "polynomial_svm(training_data,test_data,c = 0.0001,deg = 2)\n",
    "\n",
    "print(\"------------------\")\n",
    "\n",
    "polynomial_svm(training_data,test_data,c = 0.0001,deg = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 0.99551570\n",
      "Training Error: 0.00448430\n",
      "Test accuracy: 0.98349057\n",
      "Test Error: 0.01650943\n",
      "The number of Support Vectors :  76\n",
      "------------------\n",
      "Training Accuracy: 0.99551570\n",
      "Training Error: 0.00448430\n",
      "Test accuracy: 0.97877358\n",
      "Test Error: 0.02122642\n",
      "The number of Support Vectors :  25\n"
     ]
    }
   ],
   "source": [
    "polynomial_svm(training_data,test_data,0.001,2)\n",
    "\n",
    "print(\"------------------\")\n",
    "\n",
    "polynomial_svm(training_data,test_data,0.001,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 0.99551570\n",
      "Training Error: 0.00448430\n",
      "Test accuracy: 0.98113208\n",
      "Test Error: 0.01886792\n",
      "The number of Support Vectors :  34\n",
      "------------------\n",
      "Training Accuracy: 0.99615631\n",
      "Training Error: 0.00384369\n",
      "Test accuracy: 0.97877358\n",
      "Test Error: 0.02122642\n",
      "The number of Support Vectors :  23\n"
     ]
    }
   ],
   "source": [
    "polynomial_svm(training_data,test_data,0.01,2)\n",
    "\n",
    "print(\"------------------\")\n",
    "\n",
    "polynomial_svm(training_data,test_data,0.01,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 0.99679693\n",
      "Training Error: 0.00320307\n",
      "Test accuracy: 0.98113208\n",
      "Test Error: 0.01886792\n",
      "The number of Support Vectors :  24\n",
      "------------------\n",
      "Training Accuracy: 0.99679693\n",
      "Training Error: 0.00320307\n",
      "Test accuracy: 0.97877358\n",
      "Test Error: 0.02122642\n",
      "The number of Support Vectors :  21\n"
     ]
    }
   ],
   "source": [
    "polynomial_svm(training_data,test_data,1,2)\n",
    "\n",
    "print(\"------------------\")\n",
    "\n",
    "polynomial_svm(training_data,test_data,1,5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### (i) When C = 0.0001, training error is higher at Q = 5 : False <br>\n",
    "###### (ii) When C = 0.001, the number of support vectors is lower at Q = 5. : True <br>\n",
    "###### (iii) When C = 0.01, training error is higher at Q = 5. : False <br>\n",
    "###### (iv) When C = 1, test error is lower at Q = 5. False <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### d) Radial Basis Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def radial_svm(training_data,test_data,c,gamm = \"auto\"):\n",
    "    x = training_data[:,1:]\n",
    "    y = []\n",
    "    for i in training_data:\n",
    "        y.append(i[0])\n",
    "    y = np.array(y)\n",
    "    polynomial_svm = SVC(C = c, kernel = \"rbf\",gamma=gamm)\n",
    "    polynomial_svm.fit(x,y)\n",
    "   \n",
    "\n",
    "    train_outcome = polynomial_svm.predict(x)\n",
    "    train_result= []\n",
    "    for i in range(len(x)):\n",
    "        if train_outcome[i] == y[i]:\n",
    "            train_result.append(True)\n",
    "        else:\n",
    "            train_result.append(False)\n",
    "\n",
    "    train_accuracy = train_result.count(True)/len(x)\n",
    "    print(\"Training Accuracy: %.8f\" % train_accuracy)\n",
    "\n",
    "    train_error = 1-train_accuracy\n",
    "    print(\"Training Error: %.8f\" % train_error)\n",
    "\n",
    "\n",
    "    test_outcome = polynomial_svm.predict(test_data[:,1:])\n",
    "    test_result= []\n",
    "    for i in range(len(test_data)):\n",
    "        if test_outcome[i] == test_data[i][0]:\n",
    "            test_result.append(True)\n",
    "        else:\n",
    "            test_result.append(False)\n",
    "\n",
    "    test_accuracy = test_result.count(True)/len(test_data)\n",
    "\n",
    "    print(\"Test accuracy: %.8f\" % test_accuracy)\n",
    "    test_error = 1- test_accuracy\n",
    "    print(\"Test Error: %f\" % test_error)\n",
    "    support_vectors = polynomial_svm.support_vectors_\n",
    "    print(\"The number of Support Vectors : \",len(support_vectors))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 0.99615631\n",
      "Training Error: 0.00384369\n",
      "Test accuracy: 0.97641509\n",
      "Test Error: 0.023585\n",
      "The number of Support Vectors :  403\n",
      "------------------\n",
      "Training Accuracy: 0.99551570\n",
      "Training Error: 0.00448430\n",
      "Test accuracy: 0.97877358\n",
      "Test Error: 0.021226\n",
      "The number of Support Vectors :  31\n",
      "------------------\n",
      "Training Accuracy: 0.99679693\n",
      "Training Error: 0.00320307\n",
      "Test accuracy: 0.98113208\n",
      "Test Error: 0.018868\n",
      "The number of Support Vectors :  22\n",
      "------------------\n",
      "Training Accuracy: 0.99743754\n",
      "Training Error: 0.00256246\n",
      "Test accuracy: 0.97641509\n",
      "Test Error: 0.023585\n",
      "The number of Support Vectors :  20\n",
      "------------------\n",
      "Training Accuracy: 0.99935939\n",
      "Training Error: 0.00064061\n",
      "Test accuracy: 0.97641509\n",
      "Test Error: 0.023585\n",
      "The number of Support Vectors :  17\n"
     ]
    }
   ],
   "source": [
    "radial_svm(training_data,test_data,c = 0.01,gamm = 1)\n",
    "\n",
    "print(\"------------------\")\n",
    "\n",
    "radial_svm(training_data,test_data,c = 1,gamm = 1)\n",
    "\n",
    "print(\"------------------\")\n",
    "\n",
    "radial_svm(training_data,test_data,c = 100,gamm= 1)\n",
    "\n",
    "print(\"------------------\")\n",
    "\n",
    "radial_svm(training_data,test_data,c = 10000,gamm = 1)\n",
    "\n",
    "print(\"------------------\")\n",
    "\n",
    "radial_svm(training_data,test_data,c = 1000000,gamm = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Lowest Training Error is obtained when C = 1000000;Training Error = 0.00128123 <br>\n",
    "###### Lowest Test Error is obtained when C = 100; Test Error is 0.018868 <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "A Support Vector Machine (SVM) is a discriminative classifier formally defined by a separating hyperplane. In other words, given labeled training data the algorithm outputs a hyperplane which maximized distance between two planes.\n",
    "The data set consists of digits i.e class(\"1\" = +1; \"5\" = -1) with 2 features/attributes.\n",
    "The data set contains of 1561 training samples and 424 test data.\n",
    "I have trained the data on Linear Kernel, Polynomial Kernels with different Degrre's, Gaussian Kernel with different values for C\n",
    "\n",
    "- Linear Kernel\n",
    "\n",
    "|  S.no  | No of Training Sample  | Training Error | Test Error |\n",
    "|--------|------------------------|----------------|---------------|\n",
    "| 1      | Full Training Set      | 0.00384369     | 0.02122642    |\n",
    "| 2      | First 50 Samples Only  | 0.00000000     | 0.01886792    |\n",
    "| 3      | First 100 Samples Only | 0.00000000     | 0.01886792    |\n",
    "| 4      | First 200 Samples Only | 0.00500000     | 0.01886792    |\n",
    "| 5      | First 800 Samples Only | 0.00250000     | 0.01886792    |\n",
    "\n",
    "- Polynomial Kernel\n",
    "\n",
    "|  S.no  | C      | Degree | Training Error | Test Error |\n",
    "|--------|--------|--------|----------------|---------------|\n",
    "| 1      | 0.0001 | 2      | 0.00896861     | 0.01650943    |\n",
    "| 2      | 0.0001 | 5      | 0.00448430     | 0.01886792    |\n",
    "| 3      | 0.001  | 2      | 0.00448430     | 0.01650943    |\n",
    "| 4      | 0.001  | 5      | 0.00448430     | 0.02122642    |\n",
    "| 5      | 0.01   | 2      | 0.00448430     | 0.01886792    |\n",
    "| 6      | 0.01   | 5      | 0.00384369     | 0.02122642    |\n",
    "| 7      | 1      | 2      | 0.00320307     | 0.01886792    |\n",
    "| 8      | 1      | 5      | 0.00320307     | 0.02122642    |\n",
    "\n",
    "- Gaussian Kernel\n",
    "\n",
    "|  S.no  | C       | Training Error | Test Error |\n",
    "|--------|---------|----------------|---------------|\n",
    "| 1      | 0.01    | 0.00384369     | 0.021226      |\n",
    "| 2      | 1       | 0.00448430     | 0.021226      |\n",
    "| 3      | 100     | 0.00320307     | 0.018868      |\n",
    "| 4      | 10000   | 0.00256246     | 0.018868      |\n",
    "| 5      | 1000000 | 0.00128123     | 0.021226      |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5) GISETTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Get Gisette Data\n",
    "def gisette_getdata():\n",
    "    \n",
    "    with open(\"data/gisette_train.data\") as f:\n",
    "        training_x = f.readlines()\n",
    "        training_x = [line.rstrip(\"\\n\") for line in training_x]\n",
    "        training_x = [list(map(float, line.split())) for line in training_x]\n",
    "        training_x = np.array(training_x)\n",
    "                    \n",
    "    with open(\"data/gisette_train.labels\") as f:\n",
    "        training_y = f.readlines()\n",
    "        training_y = [line.rstrip(\"\\n\") for line in training_y]\n",
    "        training_y = [list(map(float, line.split())) for line in training_y]\n",
    "        training_y = np.array(training_y)\n",
    "\n",
    "    train_set = np.hstack((training_y,training_x))\n",
    "    \n",
    "    print (\"Number of records in training data: %d\" % len(train_set))\n",
    "    \n",
    "    \n",
    "    with open(\"data/gisette_valid.data\") as f:\n",
    "        test_x = f.readlines()\n",
    "        test_x = [line.rstrip(\"\\n\") for line in test_x]\n",
    "        test_x = [list(map(float, line.split())) for line in test_x]\n",
    "        test_x = np.array(test_x)\n",
    "\n",
    "    with open(\"data/gisette_valid.labels\") as f:\n",
    "        test_y = f.readlines()\n",
    "        test_y = [line.rstrip(\"\\n\") for line in test_y]\n",
    "        test_y = [list(map(float, line.split())) for line in test_y]\n",
    "        test_y = np.array(test_y)\n",
    "    \n",
    "    test_set = np.hstack((test_y,test_x))\n",
    "    \n",
    "    train_set = np.array(train_set)\n",
    "    test_set = np.array(test_set)\n",
    "    \n",
    "    print (\"Number of records in test data: %d\" % len(test_set))\n",
    "\n",
    "    return train_set,test_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of records in training data: 6000\n",
      "Number of records in test data: 1000\n"
     ]
    }
   ],
   "source": [
    "training_set,test_set  = gisette_getdata()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### a) Linear SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 1.00000000\n",
      "Training Error: 0.00000000\n",
      "Test accuracy: 0.97600000\n",
      "Test Error: 0.02400000\n",
      "The number of Support Vectors :  1084\n"
     ]
    }
   ],
   "source": [
    "linear_svm(training_set,test_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### b) RBF Kernel, Polynomial Kernel "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 1.00000000\n",
      "Training Error: 0.00000000\n",
      "Test accuracy: 0.97900000\n",
      "Test Error: 0.02100000\n",
      "The number of Support Vectors :  1755\n"
     ]
    }
   ],
   "source": [
    "polynomial_svm(training_set,test_set,c = 1,deg = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 1.00000000\n",
      "Training Error: 0.00000000\n",
      "Test accuracy: 0.50000000\n",
      "Test Error: 0.500000\n",
      "The number of Support Vectors :  6000\n"
     ]
    }
   ],
   "source": [
    "radial_svm(training_set,test_set,c = 1,gamm = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "source": [
    "###### On the Gisette Data Set the all the three kernels i.e Linear Kernel, Polynomial Kernel and Gaussian Kernel Give Training Error of 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "The problem is to separate the highly confusible digits ‘4’ and ‘9’.\n",
    "The data set contains of 6000 training samples and 1000 samples of test data(Validation Set).\n",
    "I have trained the data on Linear Kernel, Polynomial Kernel, Gaussian Kernel\n",
    "\n",
    "|  S.no  | Type of Kernel                       | Training Error | Testing Error |\n",
    "|--------|--------------------------------------|----------------|---------------|\n",
    "| 1      | Linear Kernel                        | 0.00000000     | 0.02400000    |\n",
    "| 2      | Polynomial Kernel(C = 1, Degree = 2) | 0.00000000     | 0.02100000    |\n",
    "| 3      | Gaussian Kernel(Gamma = 0.001)       | 0.00000000     | 0.500000      |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6) Random Forests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(a) Write your own random forest classifier (this should be relatively easy, given you have written your own decision tree code) to apply to the Spam dataset [Data](https://web.stanford.edu/~hastie/ElemStatLearn//datasets/spam.data),[Information](https://web.stanford.edu/~hastie/ElemStatLearn//datasets/spam.info.txt). Use 30% of the provided data as test data and the remaining for training. Compare your results in terms of accuracy and time taken with Scikitlearn’s built-in random forest classifier."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### My Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#The following Decision Tree Code has been written in Assignment 1\n",
    "class DecisionTree():\n",
    "    tree = {}\n",
    "    no_nodes = 0\n",
    "    #Splits the data to two np arrays left and right based on the attribute and threshold\n",
    "    def data_split(self,training_set,attr,thresh):\n",
    "        left = []\n",
    "        right = []\n",
    "        \n",
    "        for i in training_set:\n",
    "            \n",
    "            if i[attr] <= thresh:\n",
    "                left.append(i)\n",
    "            \n",
    "            else:\n",
    "                right.append(i)\n",
    "        \n",
    "        left = np.array(left)\n",
    "        right = np.array(right)\n",
    "        return left,right\n",
    "\n",
    "    #Entropy calculation where left array contains l_one one's l_zero zero's and so on for right array\n",
    "    def entropy_change(self, l_one,l_zero,r_one,r_zero):\n",
    "        \n",
    "        #Calculation for left array\n",
    "        tot_left = l_one+l_zero\n",
    "        left_part = 0\n",
    "        \n",
    "        if tot_left!=0:\n",
    "        \n",
    "            if l_one!=0:\n",
    "                left_part += (l_one/tot_left)*math.log(l_one/tot_left)\n",
    "            \n",
    "            if l_zero!=0:\n",
    "                left_part += (l_zero/tot_left)*math.log(l_zero/tot_left)\n",
    "\n",
    "\n",
    "        #Calculation for left array\n",
    "        tot_right = r_one + r_zero\n",
    "        right_part = 0\n",
    "        \n",
    "        if tot_right!=0:\n",
    "        \n",
    "            if r_one!=0:\n",
    "                right_part += (r_one/tot_right)*math.log(r_one/tot_right)\n",
    "            \n",
    "            if r_zero!=0:\n",
    "                right_part += (r_zero/tot_right)*math.log(r_zero/tot_right)\n",
    "\n",
    "\n",
    "                \n",
    "        #Weighted Average\n",
    "        total_length = tot_left + tot_right\n",
    "        \n",
    "        left_part = (tot_left/total_length) * left_part\n",
    "        \n",
    "        right_part = (tot_right/total_length) * right_part\n",
    "\n",
    "        return -(left_part+right_part)\n",
    "    \n",
    "    #Ginni Index calculation where left array contains l_one one's l_zero zero's and so on for right array\n",
    "    def calc_ginni(self, l_one,l_zero,r_one,r_zero):\n",
    "        print(\"GINI\")\n",
    "        \n",
    "        #Calculation for left array\n",
    "        tot_left = l_one+l_zero\n",
    "        left_part = 0\n",
    "        \n",
    "        if tot_left!=0:\n",
    "        \n",
    "            left_part += (l_one/tot_left)**2\n",
    "            left_part += (l_zero/tot_left)**2\n",
    "        \n",
    "        left_part = 1-left_part\n",
    "\n",
    "        \n",
    "        #Calculation for left array\n",
    "        tot_right = r_one + r_zero\n",
    "        right_part = 0\n",
    "        \n",
    "        if tot_right!=0:\n",
    "        \n",
    "            right_part += (r_one/tot_right)**2\n",
    "            right_part += (r_zero/tot_right)**2\n",
    "        \n",
    "        right_part = 1-right_part;\n",
    "\n",
    "        \n",
    "        #Weighted Average\n",
    "        total = tot_left + tot_right\n",
    "        \n",
    "        left_part = (tot_left/total) * left_part\n",
    "        \n",
    "        right_part = (tot_right/total) * right_part\n",
    "\n",
    "        return (left_part+right_part)\n",
    "    \n",
    "    \n",
    "    #Selecting attributes based on entropy calculations\n",
    "    def select_attribute(self,training_set,attributes,max_attributes,criterion = \"entropy\", min_entropy = 0):\n",
    "\n",
    "        \n",
    "        #Picking m attributes among all the attributes\n",
    "        attributes_remaining = np.random.choice(len(attributes),max_attributes,replace = False)\n",
    "\n",
    "        training_set = np.transpose(training_set)\n",
    "\n",
    "        best_entropy = math.inf\n",
    "        \n",
    "        best_attr = []\n",
    "        \n",
    "        #For each Attribute in attributes remaining, pick the best attribute\n",
    "        for i in attributes_remaining:\n",
    "        \n",
    "            attr_column = np.column_stack((training_set[i],training_set[-1]))\n",
    "            attr_column = attr_column[np.argsort(attr_column[:, 0])]\n",
    "            \n",
    "            \n",
    "            total_ones = sum(attr_column[:,-1])\n",
    "            total_zeros = len(attr_column[:,-1])-total_ones\n",
    "\n",
    "            if criterion == \"ginni-index\":\n",
    "                ith_best = self.calc_ginni(total_ones,total_zeros,0,0)\n",
    "                idx = math.inf\n",
    "            else:\n",
    "                ith_best  = self.entropy_change(total_ones,total_zeros,0,0)\n",
    "                idx = math.inf\n",
    "\n",
    "            \n",
    "            ones_tillnow = 0\n",
    "            zeros_tillnow = 0\n",
    "            \n",
    "            #In the ith attribute pick the best possible threshold\n",
    "            for j in range(len(attr_column)):\n",
    "                \n",
    "                if attr_column[j][1]==0:\n",
    "                    zeros_tillnow += 1\n",
    "                \n",
    "                else:\n",
    "                    ones_tillnow +=1\n",
    "                \n",
    "                if criterion == \"ginni-index\":\n",
    "                    current = self.calc_ginni(ones_tillnow, zeros_tillnow, total_ones-ones_tillnow,total_zeros-zeros_tillnow)\n",
    "                else:\n",
    "                    current  = self.entropy_change(ones_tillnow, zeros_tillnow, total_ones-ones_tillnow,total_zeros-zeros_tillnow)\n",
    "                   \n",
    "                \n",
    "                if current < ith_best:\n",
    "                \n",
    "                    ith_best = current\n",
    "                    idx = j\n",
    "\n",
    "                    \n",
    "            if ith_best < best_entropy:\n",
    "                  \n",
    "                    best_entropy = ith_best\n",
    "                    \n",
    "                    if idx!=math.inf:\n",
    "                        best_attr = [i,attr_column[idx][0]]\n",
    "                    \n",
    "                    else:\n",
    "                        best_attr = [i,idx]\n",
    "            if best_entropy <= min_entropy:\n",
    "                best_attr = [0,math.inf]\n",
    "\n",
    "        return best_attr\n",
    "\n",
    "    \n",
    "    #Function call to build the tree and return the final tree in the form of a dicitonary \n",
    "    def build_tree(self,training_set,attributes_remaining,criterion,min_entropy,max_attributes):\n",
    "\n",
    "        #Finding the best attribute and the corresponding threshold\n",
    "        attr,thresh = self.select_attribute(training_set,attributes_remaining,max_attributes, criterion,min_entropy)\n",
    "        \n",
    "        #Split the data into two arrays left and right arrays based on the attr and threshold\n",
    "        left,right = self.data_split(training_set,attr,thresh)\n",
    "\n",
    "        #If the length of either left or right is 0 this means we cannot split it further we just return the most popular value\n",
    "        if len(left)==0 or len(right)==0:\n",
    "            \n",
    "            nonzero = np.count_nonzero(training_set[:,-1])\n",
    "            \n",
    "            zeros = len(training_set[:,-1]) - nonzero\n",
    "\n",
    "            if zeros >= nonzero:\n",
    "                return 0.0\n",
    "            else:\n",
    "                return 1.0\n",
    "\n",
    "        \n",
    "        #Build Left Subtree and get the left subtree in left_tree\n",
    "        left_tree = self.build_tree(left,attributes_remaining,criterion,min_entropy,max_attributes)\n",
    "        \n",
    "        #Build Right Subtree and get the right subtree in right_tree        \n",
    "        right_tree = self.build_tree(right,attributes_remaining,criterion,min_entropy,max_attributes)\n",
    "\n",
    "        \n",
    "        #Store left subtree, right subtree, attribute selected at this node and threshold in a dictionary\n",
    "        final = {\"left\":left_tree,\"right\": right_tree,\"attr\": attr,\"thresh\":thresh}\n",
    "        self.no_nodes+=1\n",
    "        return final\n",
    "\n",
    "\n",
    "    #Calls buildtree function which returns the final tree \n",
    "    def learn(self, training_set,criterion,min_entropy,max_attributes):\n",
    "\n",
    "        training_set = np.array(training_set)\n",
    "\n",
    "        attributes_remaining = np.array(range(0,training_set.shape[1]-1))\n",
    "\n",
    "        self.tree = self.build_tree(training_set,attributes_remaining,criterion,min_entropy,max_attributes)\n",
    "\n",
    "    #Given a test instance we recursively go to left or right based on the attribute and threshold at the node\n",
    "    def find_ans(self,node,test_instance):\n",
    "\n",
    "        #Base Case\n",
    "        if type(node)==float:\n",
    "            return node\n",
    "\n",
    "        #Recurse Down the tree\n",
    "        if type(node)==dict:\n",
    "            \n",
    "            attr = node[\"attr\"]\n",
    "            thresh = node[\"thresh\"]\n",
    "\n",
    "            #Depending on the threhold value either go left or right\n",
    "            if test_instance[attr] <=thresh:\n",
    "                return self.find_ans(node[\"left\"],test_instance)\n",
    "            else:\n",
    "                return self.find_ans(node[\"right\"],test_instance)\n",
    "\n",
    "\n",
    "    #Calls find ans which recursively finds the ans\n",
    "    def classify(self, test_instance):\n",
    "        \n",
    "        result = self.find_ans(self.tree,test_instance)\n",
    "        \n",
    "        return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#random_pick takes data and returns a data set with same length by picking by replacement from the original set\n",
    "def random_pick(data):\n",
    "    \n",
    "    sample = np.random.choice(len(data),len(data),replace = True)\n",
    "    \n",
    "    present = np.zeros(len(data))\n",
    "    \n",
    "    for i in sample:\n",
    "        present[i] += 1\n",
    "    \n",
    "    set1 = []\n",
    "    for i in range(len(data)):\n",
    "        if present[i] >= 1:\n",
    "            for j in range(int(present[i])):\n",
    "                set1.append(data[i])\n",
    "\n",
    "    \n",
    "    set1 = np.array(set1)\n",
    "\n",
    "    \n",
    "    return set1,present"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Get Input\n",
    "def spam_get_input():\n",
    "    with open(\"data/spam.data\") as f:\n",
    "        data = f.readlines()\n",
    "        data = [line.rstrip(\"\\n\") for line in data]\n",
    "        data = [list(map(float, line.split(\" \"))) for line in data]\n",
    "        data = np.array(data)\n",
    "        \n",
    "    data = np.random.permutation(data)\n",
    "\n",
    "    training_set = []\n",
    "    test_set = []\n",
    "    for i in range(len(data)):\n",
    "        if i < round(0.7*len(data)):\n",
    "            training_set.append(data[i])\n",
    "        else:\n",
    "            test_set.append(data[i])\n",
    "                \n",
    "    training_set = np.array(training_set)\n",
    "    test_set = np.array(test_set)\n",
    "\n",
    "    return training_set,test_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Function which runs the decision tree\n",
    "def run_random_forest(no_trees, max_attributes, criterion,min_entropy = 0):\n",
    "\n",
    "    training_set,test_set = spam_get_input()\n",
    "\n",
    "    print(\"---------------------\")\n",
    "\n",
    "    print(\"No of Trees: \",no_trees,sep = \" \")\n",
    "    print(\"No of Maximum Attributes at Node Splitting: \",max_attributes,sep =\" \")\n",
    "    \n",
    "    trees = []\n",
    "    marker = []\n",
    "    for j in range(no_trees):\n",
    "        training_subset,mark = random_pick(training_set)\n",
    "        marker.append(mark)\n",
    "\n",
    "        tree = DecisionTree()\n",
    "    \n",
    "        # Construct a tree using training set\n",
    "        tree.learn( training_subset, criterion, min_entropy,max_attributes)\n",
    "        trees.append(tree)\n",
    "\n",
    "\n",
    "\n",
    "    # Classify the test set using the trees we just constructed\n",
    "    results = []\n",
    "    for instance in test_set:\n",
    "        result = []\n",
    "        for i in range(no_trees):\n",
    "            \n",
    "            result.append(trees[i].classify(instance[:-1]))\n",
    "    \n",
    "        \n",
    "        if result.count(True) > result.count(False):\n",
    "            results.append( 1 == float(instance[-1]))\n",
    "        else:\n",
    "            results.append( 0 == float(instance[-1]))\n",
    "\n",
    "\n",
    "    # Accuracy\n",
    "    accuracy = float(results.count(True))/float(len(results))\n",
    "\n",
    "    print(\"Test accuracy: %.8f\" % accuracy)\n",
    "    print(\"Test Error: %.8f\" % (1-accuracy))\n",
    "  \n",
    "\n",
    "    #Calculate the OOB Error\n",
    "\n",
    "    oob = []\n",
    "    marker = np.array(marker)\n",
    "    #print(marker.shape)\n",
    "    for i in range(len(training_set)):\n",
    "        result = []\n",
    "        for j in range(no_trees):\n",
    "            if marker[j][i] != 1:\n",
    "                result.append(trees[j].classify(training_set[i][:-1]))\n",
    "        \n",
    "        if result.count(True) > result.count(False):\n",
    "            oob.append(1==float(training_set[i][-1]))\n",
    "        else:\n",
    "            oob.append(0==float(training_set[i][-1]))\n",
    "            \n",
    "    oob_error =  1- float(oob.count(True))/float(len(oob))\n",
    "    \n",
    "    print(\"OOB Error: %.8f\" % oob_error)\n",
    "    print(\"Completed\")\n",
    "    print(\"---------------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest Using Sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def sklearn_Randomforest(no_trees,m):\n",
    "    training_set,test_set = spam_get_input()\n",
    "    \n",
    "    print(\"---------------------\")    \n",
    "    print(\"No of Trees: \",no_trees,sep = \" \")\n",
    "    print(\"No of Maximum Attributes at Node Splitting: \",m,sep =\" \")\n",
    "    \n",
    " \n",
    "    random_forest = RandomForestClassifier(n_estimators = no_trees,max_features= m, n_jobs =-1)\n",
    "    training_set = np.array(training_set)\n",
    "    x = training_set[:,:-1]\n",
    "    y = training_set[:,-1]\n",
    "    random_forest.fit(x,y)\n",
    "    #print(random_forest.feature_importances_)\n",
    "\n",
    "    predicted_result = random_forest.predict(test_set[:,:-1])\n",
    "    actual_result = test_set[:,-1]\n",
    "    \n",
    "    # Classify the test set using the Random forest we\n",
    "    results = []\n",
    "    for i in range(len(test_set)):\n",
    "        results.append( predicted_result[i] == actual_result[i])\n",
    "    \n",
    "\n",
    "    # Accuracy\n",
    "    accuracy = float(results.count(True))/float(len(results))\n",
    "\n",
    "    print(\"accuracy: %.8f\" % accuracy)\n",
    "    print(\"Completed\")\n",
    "    print(\"---------------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "#### Comparing My Random Forest With Sklearns Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------\n",
      "No of Trees:  25\n",
      "No of Maximum Attributes at Node Splitting:  8\n",
      "Test accuracy: 0.93623188\n",
      "Test Error: 0.06376812\n",
      "OOB Error: 0.04036014\n",
      "Completed\n",
      "---------------------\n",
      "Time:  45.40841455300688\n",
      "---------------------\n",
      "No of Trees:  25\n",
      "No of Maximum Attributes at Node Splitting:  22\n",
      "Test accuracy: 0.94637681\n",
      "Test Error: 0.05362319\n",
      "OOB Error: 0.02732071\n",
      "Completed\n",
      "---------------------\n",
      "Time:  116.17177796500619\n"
     ]
    }
   ],
   "source": [
    "#Running My random Forest \n",
    "start = timeit.default_timer()\n",
    "\n",
    "run_random_forest(no_trees=25,max_attributes =8, criterion = \"entropy\")\n",
    "\n",
    "stop = timeit.default_timer()\n",
    "print('Time: ', stop - start)  \n",
    "\n",
    "start = timeit.default_timer()\n",
    "\n",
    "run_random_forest(no_trees=25,max_attributes =22, criterion = \"entropy\")\n",
    "\n",
    "stop = timeit.default_timer()\n",
    "print('Time: ', stop - start)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------\n",
      "No of Trees:  25\n",
      "No of Maximum Attributes at Node Splitting:  8\n",
      "accuracy: 0.94782609\n",
      "Completed\n",
      "---------------------\n",
      "Time:  0.29053281500091543\n",
      "---------------------\n",
      "No of Trees:  25\n",
      "No of Maximum Attributes at Node Splitting:  22\n",
      "accuracy: 0.95000000\n",
      "Completed\n",
      "---------------------\n",
      "Time:  0.40412301600008504\n"
     ]
    }
   ],
   "source": [
    "#Running Sklearn's Random Forest\n",
    "\n",
    "start = timeit.default_timer()\n",
    "\n",
    "sklearn_Randomforest(no_trees = 25,m = 8)\n",
    "\n",
    "stop = timeit.default_timer()\n",
    "print('Time: ', stop - start)  \n",
    "\n",
    "start = timeit.default_timer()\n",
    "\n",
    "sklearn_Randomforest(no_trees = 25,m = 22)\n",
    "\n",
    "stop = timeit.default_timer()\n",
    "print('Time: ', stop - start)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conclusion\n",
    "----------\n",
    "- Sklearns Random Forest takes very less time compared to my implementation of Random Forest.\n",
    "- Time taken by my random forest when m = 8 and no of trees = 25 is on average 45 secs whereas the time taken by sklearns Random Forest for the same input is always less than 1 sec ~0.3\n",
    "- Time taken by my random forest when m = 22 and no of trees = 25 is on average 115 secs whereas the time taken by sklearns Random Forest for the same input is less than 1sec ~0.35\n",
    "- sklearns random Forest trains the trees paralelly when n_jobs is set to -1\n",
    "\n",
    "- Accuracy obtained by my random Forest for m = 8 and no of trees = 25 is on average 94 and the accuracy obtained by sklearn's Random Forest on average is 95%\n",
    "- Accuracy given by both is almost the same between 92 - 96% for both. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (b) Explore the sensitivity of Random Forests to the parameter m (no features used for best split)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------ 2 ------\n",
      "---------------------\n",
      "No of Trees:  25\n",
      "No of Maximum Attributes at Node Splitting:  2\n",
      "Test accuracy: 0.92101449\n",
      "Test Error: 0.07898551\n",
      "OOB Error: 0.05371003\n",
      "Completed\n",
      "---------------------\n",
      "------ 6 ------\n",
      "---------------------\n",
      "No of Trees:  25\n",
      "No of Maximum Attributes at Node Splitting:  6\n",
      "Test accuracy: 0.94637681\n",
      "Test Error: 0.05362319\n",
      "OOB Error: 0.04160199\n",
      "Completed\n",
      "---------------------\n",
      "------ 10 ------\n",
      "---------------------\n",
      "No of Trees:  25\n",
      "No of Maximum Attributes at Node Splitting:  10\n",
      "Test accuracy: 0.93913043\n",
      "Test Error: 0.06086957\n",
      "OOB Error: 0.03477181\n",
      "Completed\n",
      "---------------------\n",
      "------ 14 ------\n",
      "---------------------\n",
      "No of Trees:  25\n",
      "No of Maximum Attributes at Node Splitting:  14\n",
      "Test accuracy: 0.94492754\n",
      "Test Error: 0.05507246\n",
      "OOB Error: 0.03290903\n",
      "Completed\n",
      "---------------------\n",
      "------ 18 ------\n",
      "---------------------\n",
      "No of Trees:  25\n",
      "No of Maximum Attributes at Node Splitting:  18\n",
      "Test accuracy: 0.95072464\n",
      "Test Error: 0.04927536\n",
      "OOB Error: 0.03352996\n",
      "Completed\n",
      "---------------------\n",
      "------ 22 ------\n",
      "---------------------\n",
      "No of Trees:  25\n",
      "No of Maximum Attributes at Node Splitting:  22\n",
      "Test accuracy: 0.94130435\n",
      "Test Error: 0.05869565\n",
      "OOB Error: 0.02732071\n",
      "Completed\n",
      "---------------------\n",
      "------ 26 ------\n",
      "---------------------\n",
      "No of Trees:  25\n",
      "No of Maximum Attributes at Node Splitting:  26\n",
      "Test accuracy: 0.94565217\n",
      "Test Error: 0.05434783\n",
      "OOB Error: 0.02701025\n",
      "Completed\n",
      "---------------------\n",
      "------ 30 ------\n",
      "---------------------\n",
      "No of Trees:  25\n",
      "No of Maximum Attributes at Node Splitting:  30\n",
      "Test accuracy: 0.95144928\n",
      "Test Error: 0.04855072\n",
      "OOB Error: 0.03508227\n",
      "Completed\n",
      "---------------------\n",
      "------ 34 ------\n",
      "---------------------\n",
      "No of Trees:  25\n",
      "No of Maximum Attributes at Node Splitting:  34\n",
      "Test accuracy: 0.92826087\n",
      "Test Error: 0.07173913\n",
      "OOB Error: 0.03290903\n",
      "Completed\n",
      "---------------------\n",
      "------ 38 ------\n",
      "---------------------\n",
      "No of Trees:  25\n",
      "No of Maximum Attributes at Node Splitting:  38\n",
      "Test accuracy: 0.93913043\n",
      "Test Error: 0.06086957\n",
      "OOB Error: 0.02980441\n",
      "Completed\n",
      "---------------------\n",
      "------ 42 ------\n",
      "---------------------\n",
      "No of Trees:  25\n",
      "No of Maximum Attributes at Node Splitting:  42\n",
      "Test accuracy: 0.94710145\n",
      "Test Error: 0.05289855\n",
      "OOB Error: 0.02701025\n",
      "Completed\n",
      "---------------------\n",
      "------ 46 ------\n",
      "---------------------\n",
      "No of Trees:  25\n",
      "No of Maximum Attributes at Node Splitting:  46\n",
      "Test accuracy: 0.94492754\n",
      "Test Error: 0.05507246\n",
      "OOB Error: 0.02576839\n",
      "Completed\n",
      "---------------------\n",
      "------ 50 ------\n",
      "---------------------\n",
      "No of Trees:  25\n",
      "No of Maximum Attributes at Node Splitting:  50\n",
      "Test accuracy: 0.93333333\n",
      "Test Error: 0.06666667\n",
      "OOB Error: 0.02980441\n",
      "Completed\n",
      "---------------------\n",
      "------ 54 ------\n",
      "---------------------\n",
      "No of Trees:  25\n",
      "No of Maximum Attributes at Node Splitting:  54\n",
      "Test accuracy: 0.94855072\n",
      "Test Error: 0.05144928\n",
      "OOB Error: 0.03290903\n",
      "Completed\n",
      "---------------------\n"
     ]
    }
   ],
   "source": [
    "# We try to run our random forest for different values of m. m  = (2, 6, 8, .... 50, 54)\n",
    "for j in range(2,57,4):\n",
    "    print(\"------\",j,\"------\")\n",
    "    run_random_forest(no_trees=25,max_attributes =j, criterion = \"entropy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The test Error is more in the beginning when the m is sqrt(no of attributes) the test error is low\n",
    "again in between 20-30 we see a slight peek and then from there the test error almost remains the same. For the exact plot of training error vs m see the plot in the following question."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### c) Plot the OOB (out-of-bag) error and the test error against a suitably chosen range of values for m."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Out of Bag Estimate\n",
    "\n",
    "After creating the classifiers (p trees), for each (xi,yi) in the original training set i.e. T, select all Tk which does not include (xi,yi). FOr each point (xi,yi) in select all the trees which were build without using (xi,yi) and predict (xi,yi) on only those trees. DO the above step for all the data points in T\n",
    "\n",
    "Out-of-bag estimate for the generalization error is the error rate of the out-of-bag classifier on the training set (compare it with known yi's).\n",
    "\n",
    "The values for the below graph have been generated by taking no of trees  = 25.\n",
    "<img src=\"images/6c.png\" style=\"width:400px;height:300px;\">"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
